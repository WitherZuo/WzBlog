---
title: 解决百度爬虫的问题
tags:
  - Hexo
  - 百度爬虫
categories: Hexo
titlename: 798cc8cb
date: 2019-03-28 08:26:24
updated: 2019-07-19 21:01:13
keywords: [百度爬虫, Hexo, GitHub, Coding]
---

Hexo 是一个简单高效的博客框架，使用它可以很方便地建立一个属于自己的 Blog，而且寻找托管的服务提供方也很容易，Hexo + GitHub Pages 就可以很好地满足一个静态页面的托管了。又可以省下主机的钱，如果不需要自定义域名的话，那么连购买自定义域名的钱也可以省下来。但是用 GitHub Pages 服务来托管页面也不是一个完美的办法，比如百度爬虫的问题（BaiduSpider）。   <!--more-->   

![弹出的错误信息](https://storage.live.com/items/5582C1D07E2893FB!133128?authkey=APiqr1tjl5KIc1Q "弹出的错误信息")  

GitHub 默认会阻拦百度爬虫来爬取自己的页面信息，如果使用百度 Spider 的用户代理来访问 GitHub Pages 上的页面，往往等待的是 403 Forbidden，这说明 GitHub 阻止了百度爬虫的访问请求，而原因则是跟之前的百度流量劫持有关。概括的说，有人将访问百度的流量恶意劫持到 GitHub，导致 GitHub 服务器过载几近瘫痪，再加上百度爬虫本身访问的频率较高，导致 GitHub 就彻底阻止了来自百度爬虫的流量。而且据 GitHub 官方客服的说法，基本上以后也不会有什么改变了。  

![GitHub官方的回复](https://storage.live.com/items/5582C1D07E2893FB!133127?authkey=APiqr1tjl5KIc1Q "GitHub官方的回复")  

这样各种解决方法应运而生，有使用 CDN 加速的，有使用自己的服务器进行搭建的，有用 nginx 搭反向代理的，但是无一例外都需要花钱，这跟一开始不想过多掏钱的初衷相违背，使用 Coding Pages 和 GitHub Pages “双修”，让国内线路访问 Coding，国外访问 GitHub 也是一种思路，但 Coding Pages 服务器三天一小崩，一周上不去的情况也不适合这样做（这也是目前我采用的方式）。然而并不是没有解决的方法，重点就是：不让百度的爬虫访问 GitHub 不就行了。  

其实这跟使用 Coding Pages 和 GitHub Pages，利用前者搭建后者镜像站的原理一样，我们可以设置让百度的爬虫访问镜像站，而普通用户访问原有网站即可。之前我往域名解析记录里设置的是国内（包括百度爬虫）访问 Coding Pages，而海外解析到 GitHub Pages，那么**修改 Coding Pages 的解析范围为搜索引擎就行了**，以阿里云为例（我使用的是阿里云/万网的域名解析），比如下图这样做，**将 Coding Pages 的解析路线设置为“百度”，再将 GitHub Pages 的解析记录由“海外”修改为“默认”**：  

修改 Coding Pages 的两项记录，将其中的解析记录更改为百度：    

![改动图示1](https://storage.live.com/items/5582C1D07E2893FB!133133?authkey=APiqr1tjl5KIc1Q  "改动图示1")  
![改动图示2](https://storage.live.com/items/5582C1D07E2893FB!133132?authkey=APiqr1tjl5KIc1Q  "改动图示2")  

接下来修改 GitHub Pages 的解析记录：  

![改动图示3](https://storage.live.com/items/5582C1D07E2893FB!133139?authkey=APiqr1tjl5KIc1Q "改动图示3")  
![改动图示4](https://storage.live.com/items/5582C1D07E2893FB!133138?authkey=APiqr1tjl5KIc1Q "改动图示4")  
![改动图示5](https://storage.live.com/items/5582C1D07E2893FB!133140?authkey=APiqr1tjl5KIc1Q "改动图示5")  

修改后的结果：  

![最终显示结果](https://storage.live.com/items/5582C1D07E2893FB!133134?authkey=APiqr1tjl5KIc1Q "最终显示结果")  

确认无误后，保存！这样一来，等待一段时间，在解析记录更新后，就会按照一开始计划的那样，百度爬虫会去爬取镜像站 Coding Pages 上的页面，而用户在访问的时候会进入到 GitHub Pages 的页面，至少 GitHub Pages 的访问稳定性好多了，而且说实话，GitHub Pages 的域名解析速度并不慢，日用是没有太大问题的。最后放几张截图：  

![ping截图](https://storage.live.com/items/5582C1D07E2893FB!133131?authkey=APiqr1tjl5KIc1Q "ping截图")   

可以看到，ping 的结果和 nslookup 查询的结果都已经改变，默认访问会转向 GitHub Pages，而且 ping 的速度并不算太慢。  

那么 Coding Pages 和百度 Spider 呢？  

![结果图](https://storage.live.com/items/5582C1D07E2893FB!133130?authkey=APiqr1tjl5KIc1Q "结果图")  

点进去看一下：  

![结果图详情](https://storage.live.com/items/5582C1D07E2893FB!133129?authkey=APiqr1tjl5KIc1Q "结果图详情")   
