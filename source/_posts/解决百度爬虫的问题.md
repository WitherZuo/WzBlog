---
title: 解决百度爬虫的问题
tags:
  - Hexo
  - 百度爬虫
categories: Hexo
abbrlink: 798cc8cb
date: 2019-03-28 08:26:24
keyword:
---

Hexo是一个简单高效的博客框架，使用它可以很方便地建立一个属于自己的Blog，而且寻找托管的服务提供方也很容易，Hexo+GitHub Pages就可以很好地满足一个静态页面的托管了。又可以省下主机的钱，如果不需要自定义域名的话，那么连购买自定义域名的钱也可以省下来。但是用GitHub Pages服务来托管页面也不是一个完美的办法，比如百度爬虫的问题（Baidu Spider）。   <!--more-->   

![baiduspider_error-msg.png](https://storage.live.com/items/5582C1D07E2893FB!133128?authkey=APiqr1tjl5KIc1Q)  

GitHub默认会阻拦百度爬虫来爬取自己的页面信息，如果使用百度Spider的用户代理来访问GitHub Pages上的页面，往往等待的是403 Forbidden，这说明GitHub阻止了百度爬虫的访问请求，而原因则是跟之前的百度流量劫持有关。概括的说，有人将访问百度的流量恶意劫持到GitHub，导致GitHub服务器过载几近瘫痪，再加上百度爬虫本身访问的频率较高，导致GitHub就彻底阻止了来自百度爬虫的流量。而且据GitHub官方客服的说法，基本上以后也不会有什么改变了。  

![baiduspider_whygithubblockit.png](https://storage.live.com/items/5582C1D07E2893FB!133127?authkey=APiqr1tjl5KIc1Q)  

这样各种解决方法应运而生，有使用CDN加速的，有使用自己的服务器进行搭建的，有用nginx搭反向代理的，但是无一例外都需要花钱，这跟一开始不想过多掏钱的初衷相违背，使用Coding Pages和GitHub Pages“双修”，让国内线路访问Coding，国外访问GitHub也是一种思路，但Coding Pages服务器三天一小崩，一周上不去的情况也不适合这样做（这也是目前我采用的方式）。然而并不是没有解决的方法，重点就是：不让百度的爬虫访问GitHub不就行了。  

其实这跟使用Coding Pages和GitHub Pages，利用前者搭建后者镜像站的原理一样，我们可以设置让百度的爬虫访问镜像站，而普通用户访问原有网站即可。之前我往域名解析记录里设置的是国内（包括百度爬虫）访问Coding Pages，而海外解析到GitHub Pages，那么**修改Coding Pages的解析范围为搜索引擎就行了**，以阿里云为例（我使用的是阿里云/万网的域名解析），比如下图这样做，**将Coding Pages的解析路线设置为“百度”，再将GitHub Pages的解析记录由“海外”修改为“默认”**：  

修改Coding Pages的两项记录，将其变为百度：    

![baiduspider_aliyun-change1.png](https://storage.live.com/items/5582C1D07E2893FB!133133?authkey=APiqr1tjl5KIc1Q)    

![baiduspider_aliyun-change2.png](https://storage.live.com/items/5582C1D07E2893FB!133132?authkey=APiqr1tjl5KIc1Q)

接下来修改GitHub Pages的设置记录：  

![baiduspider_change3.png](https://storage.live.com/items/5582C1D07E2893FB!133139?authkey=APiqr1tjl5KIc1Q)  

![baiduspider_change4.png](https://storage.live.com/items/5582C1D07E2893FB!133138?authkey=APiqr1tjl5KIc1Q)  

![baiduspider_change5.png](https://storage.live.com/items/5582C1D07E2893FB!133140?authkey=APiqr1tjl5KIc1Q)  

修改后的结果：  

![baiduspider_aliyun-mainui.png](https://storage.live.com/items/5582C1D07E2893FB!133134?authkey=APiqr1tjl5KIc1Q)  

确认无误后，保存！这样一来，等待一段时间，在解析记录更新后，就会按照一开始计划的那样，百度爬虫会去爬取镜像站Coding Pages上的页面，而用户在访问的时候会进入到GitHub Pages的页面，至少GitHub Pages的访问稳定性好多了，而且说实话，GitHub Pages的域名解析速度并不慢，日用是没有太大问题的。最后放几张截图：  

 ![baiduspider_ping-result.png](https://storage.live.com/items/5582C1D07E2893FB!133131?authkey=APiqr1tjl5KIc1Q)   

可以看到，ping的结果和nslookup查询的结果都已经改变，默认访问会转向GitHub Pages，而且ping的速度并不算太慢。  

那么Coding Pages和百度Spider呢？  

![baiduspider_check.png](https://storage.live.com/items/5582C1D07E2893FB!133130?authkey=APiqr1tjl5KIc1Q)

点进去看一下：  

![baiduspider_check-detail.png](https://storage.live.com/items/5582C1D07E2893FB!133129?authkey=APiqr1tjl5KIc1Q)  

<head><script defer src="https://use.fontawesome.com/releases/v5.5.0/js/all.js"></script><script defer src="https://use.fontawesome.com/releases/v5.5.0/js/v4-shims.js"></script></head><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css"><!-- AddToAny BEGIN --><div class="a2a_kit a2a_kit_size_32 a2a_default_style"><a class="a2a_button_facebook"></a><a class="a2a_button_twitter"></a><a class="a2a_button_wechat"></a><a class="a2a_button_sina_weibo"></a><a class="a2a_button_douban"></a><a class="a2a_button_copy_link"></a></div><script async src="https://static.addtoany.com/menu/page.js"></script><!-- AddToAny END -->